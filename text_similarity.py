from sentence_transformers import SentenceTransformer, util
from bert_score import BERTScorer
from fastapi import FastAPI, HTTPException
from comet import download_model, load_from_checkpoint
from pydantic import BaseModel
import time

# ëª¨ë¸ ë¡œë”©
# HuggingFaceì˜ SentenceTransFormer ë¼ì´ë¸ŒëŸ¬ë¦¬(e5, LaBSE ëª¨ë¸ ì‚¬ìš©)
model_e5 = SentenceTransformer('intfloat/multilingual-e5-large', device='cpu')
model_labse = SentenceTransformer('sentence-transformers/LaBSE', device='cpu')
# HuggingFaceì˜ bert-score íŒ¨í‚¤ì§€
model_bert = BERTScorer(
    model_type="xlm-roberta-base",
    lang="ko",                      # í† í¬ë‚˜ì´ì € ì„¤ì •ì„ ìœ„í•œ ì„ì‹œ ê°’ 
    # lang=target_lang,             # ì‚¬ìš©ì ë²ˆì—­ ì–¸ì–´ ì…ë ¥ ì‹œ ì£¼ì„ ì œê±° 
    rescale_with_baseline=False,    # ì–¸ì–´ë³„ ê°€ì¤‘ì¹˜ ì„¤ì • X
    idf=False                       # ì–¸ì–´ë³„ ê°€ì¤‘ì¹˜ ì„¤ì • X
)
# Unbabelì˜ COMET ëª¨ë¸ ì‚¬ìš©
model_comet_path = download_model("wmt20-comet-qe-da")
model_comet = load_from_checkpoint(model_comet_path)

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="Text Similarity API",
    description="ì›ë¬¸ê³¼ ë²ˆì—­ë¬¸ê°„ì˜ ìœ ì‚¬ë„ í‰ê°€ API",
    version="1.0.0"
)

# ì…ë ¥ ë°ì´í„° ëª¨ë¸ ì •ì˜
class TextPair(BaseModel):
    source_text: str    # ì›ë³¸ í…ìŠ¤íŠ¸
    target_text: str    # ë²ˆì—­ í…ìŠ¤íŠ¸

# E5, LaBSE Score
def get_similarity(model, sentence1, sentence2):
    embeddings = model.encode([sentence1, sentence2], convert_to_tensor=True)
    return util.pytorch_cos_sim(embeddings[0], embeddings[1]).item()

# BERTScore
def get_bertscore(source_text, target_text):
    P, R, F1 = model_bert.score([target_text], [source_text])
    return P.item(), R.item(), F1.item()

# Comet Score
def get_comet_score(source_text, target_text):
    # COMET ìŠ¤ì½”ì–´ ê³„ì‚° (ìµœì‹  API ë°©ì‹)
    data = [
        {
            "src": source_text,
            "mt": target_text,
        }
    ]
    model_output = model_comet.predict(data, batch_size=8, gpus=0)
    return model_output.system_score

# Score ì„ê³„ê°’ ì„¤ì •
threshold_e5=0.8
threshold_labse=0.7
threshold_bert=0.8
threshold_comet=0.5

def evaluate_text_similarity(
        source_text, 
        target_text, 
        
    ):
    start = time.time()

    similarity_e5 = get_similarity(
        model_e5, 
        f"query: {source_text}", 
        f"passage: {target_text}"
        )

    similarity_labse = get_similarity(model_labse, source_text, target_text)
    P, R, F1 = get_bertscore(source_text, target_text)
    comet_score = get_comet_score(source_text, target_text)
    
    # descriptionì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”
    descriptions = [
        "Score Explanation:",
        " â€¢ E5: ë¬¸ì¥ ë‹¨ìœ„, êµ¬ì ˆ ë“±ì„ ì„ë² ë”©í•´ cosine similarity ì¸¡ì •",
        " â€¢ LaBSE: ë¬¸ì¥ ì „ì²´ë¥¼ ì„ë² ë”©í•´ cosine similarity ì¸¡ì •",
        " â€¢ BERTScore: ê° ë‹¨ì–´ë“¤ì„ ì„ë² ë”©í•´ cosine similarity ì¸¡ì •",
        " â€¢ COMET: ì‚¬ëŒ í‰ê°€ ê¸°ë°˜ ë²ˆì—­ í’ˆì§ˆ ì ìˆ˜ ì¸¡ì •"
    ]

    # e5, LaBSE í‰ê°€
    if similarity_e5 >= threshold_e5 and similarity_labse >= threshold_labse:
        descriptions.append(
            f"âœ… ì§ì—­ ê°€ëŠ¥ì„± ë†’ìŒ (E5: {similarity_e5:.2f} â‰¥ {threshold_e5}, "
            f"LaBSE: {similarity_labse:.2f} â‰¥ {threshold_labse})"
        )
    elif similarity_e5 >= threshold_e5:
        descriptions.append(
            f"âœï¸ ì˜ì—­ ê°€ëŠ¥ì„± ìˆìŒ (E5: {similarity_e5:.2f} â‰¥ {threshold_e5}, "
            f"LaBSE: {similarity_labse:.2f} < {threshold_labse})"
        )
    elif similarity_labse >= threshold_labse:
        descriptions.append(
            f"ğŸ“– ì§ì—­ ìœ ì‚¬ì„±ë§Œ ë†’ìŒ (E5: {similarity_e5:.2f} < {threshold_e5}, "
            f"LaBSE: {similarity_labse:.2f} â‰¥ {threshold_labse})"
        )
    else:
        descriptions.append(
            f"âš ï¸ ì˜ë¯¸ ì°¨ì´ í¼ (E5: {similarity_e5:.2f}, LaBSE: {similarity_labse:.2f}); "
            "COMET score í™•ì¸ ìš”ë§"
        )

    # BERTScore í‰ê°€
    if F1 >= threshold_bert:
        descriptions.append(
            f"ğŸ‘ ë‹¨ì–´ ë‹¨ìœ„ ì˜ë¯¸ ìœ ì‚¬ë„ ìš°ìˆ˜ (BERTScore F1: {F1:.2f} â‰¥ {threshold_bert})"
        )
    else:
        descriptions.append(
            f"ğŸ‘ ë‹¨ì–´ ë‹¨ìœ„ ì˜ë¯¸ ìœ ì‚¬ë„ ë¶€ì¡± (BERTScore F1: {F1:.2f} < {threshold_bert})"
        )

    # COMET í‰ê°€ ì¶”ê°€
    if comet_score >= threshold_comet:
        descriptions.append(
            f"ğŸ¯ ë²ˆì—­ í’ˆì§ˆ ìš°ìˆ˜ (COMET: {comet_score:.2f} â‰¥ {threshold_comet})"
        )
    else:
        descriptions.append(
            f"â—ï¸ ë²ˆì—­ í’ˆì§ˆ ë¯¸í¡ (COMET: {comet_score:.2f} < {threshold_comet})"
        )

    end = time.time()
    # ìœ ì‚¬ë„ í‰ê°€ ì†Œìš”ì‹œê°„
    execution_time = end - start

    # JSON í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ ë°˜í™˜
    return {
        "source_text": source_text,
        "target_text": target_text,
        "e5_cosine_similarity": round(similarity_e5, 4),
        "labse_cosine_similarity": round(similarity_labse, 4),
        "bertscore": {
            "precision": round(P, 4),
            "recall": round(R, 4),
            "f1": round(F1, 4)
        },
        "comet_score": comet_score,
        "description" : descriptions,
        "execution_time_seconds": round(execution_time, 2)
    }

# Agent Controller
@app.post("/agent-text")
async def agent_controller(text_pair: TextPair):
    """
    ì›ë¬¸ê³¼ ë²ˆì—­ë¬¸ì˜ ìœ ì‚¬ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.
    
    - **source_text**: ì›ë³¸ í…ìŠ¤íŠ¸
    - **target_text**: ë²ˆì—­ëœ í…ìŠ¤íŠ¸
    
    Returns:
        ìœ ì‚¬ë„ í‰ê°€ ê²°ê³¼ (JSON í˜•ì‹)
    """
    try:
        result = evaluate_text_similarity(
            text_pair.source_text,
            text_pair.target_text
        )
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

